{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d50aa3d",
   "metadata": {},
   "source": [
    "# Leaf variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b5154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "if get_ipython():\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "    get_ipython().run_line_magic('autoreload', '2')\n",
    "\n",
    "import latenta as la\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77abc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = la.Dim(10000, \"cell\")\n",
    "genes = la.Dim(10000, \"gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb6e76",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3bb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.zeros((len(cells), len(genes)))\n",
    "for i in range(value.shape[0]):\n",
    "    value[i, np.random.choice(value.shape[1])] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72611a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9764a",
   "metadata": {},
   "source": [
    "### Memory loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18cf353",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = la.variables.loaders.MemoryLoader(value)\n",
    "fixed = la.Fixed(loader, definition = la.Definition([cells, genes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b641a1",
   "metadata": {},
   "source": [
    "### Sparse loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b52222",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "            if torch.is_tensor(obj):\n",
    "                size += obj.element_size() * obj.nelement()\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef66898",
   "metadata": {},
   "source": [
    "Obviously, a large difference in memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381.47050285339355"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsize(loader)/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358243a",
   "metadata": {},
   "source": [
    "Using 3GB (or more) on current GPUs would be prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6128119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_sparse = la.variables.loaders.SparseDenseMemoryLoader(la.sparse.COO.from_numpy_array(value))\n",
    "fixed_sparse = la.Fixed(loader_sparse, definition = la.Definition([cells, genes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef912de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5413875579833984"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsize(loader_sparse)/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898d75f",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241efaa6",
   "metadata": {},
   "source": [
    "There are several ways to initialize the COO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e95b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COO(row=tensor([   0,    1,    2,  ..., 9997, 9998, 9999]), col=tensor([4780, 4479, 1517,  ..., 3844, 9554, 7926]), values=tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), shape=(10000, 10000), mapping=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.sparse.COO.from_numpy_array(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfcb8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COO(row=tensor([   0,    1,    2,  ..., 9997, 9998, 9999]), col=tensor([4780, 4479, 1517,  ..., 3844, 9554, 7926]), values=tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), shape=(10000, 10000), mapping=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_scipy_coo = scipy.sparse.coo_matrix(value)\n",
    "la.sparse.COO.from_scipy_coo(value_scipy_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8e3e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COO(row=tensor([   0,    1,    2,  ..., 9997, 9998, 9999]), col=tensor([4780, 4479, 1517,  ..., 3844, 9554, 7926]), values=tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), shape=(10000, 10000), mapping=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_scipy_csr = scipy.sparse.csr_matrix(value)\n",
    "la.sparse.COO.from_scipy_csr(value_scipy_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4f142",
   "metadata": {},
   "source": [
    "#### Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1aab4",
   "metadata": {},
   "source": [
    "When data is accessed from a SparseDenseMemoryLoader, it is converted to a dense tensor. This can cause a slowdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045ddf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf97a732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4299446269869804e-06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = timeit.timeit(\"loader.get()\", number = 1, globals = globals())\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe882efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05968685192056"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = timeit.timeit(\"loader_sparse.get()\", number = 1, globals = globals())\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87d8b4",
   "metadata": {},
   "source": [
    "Speed is however more competitive when taking only a subsample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce76a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = {\"cell\":torch.tensor(range(500))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3c3c494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00203545403201133"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = timeit.timeit(\"loader.get(idx)\", number = 1, globals = globals())\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1b0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003830755944363773"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = timeit.timeit(\"loader_sparse.get(idx)\", number = 1, globals = globals())\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2b123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67f2bc5d0a4b821c8bb058df1e7f636de0fd718ca5110ddb2a5d99375a72ab00"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
